# Local Development — FL Stroke Prediction

Zero Docker, zero Kubernetes. Pure Python.

## Setup

```bash
cd local_dev
python -m venv fl_env
fl_env\Scripts\activate        # Windows
pip install -r requirements.txt
```

## Step 1 — Get the data

Download from Kaggle: https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset  
Place the CSV at:
```
local_dev/data/raw/healthcare-dataset-stroke-data.csv
```

## Step 2 — Preprocess & split into 3 hospitals

```bash
python preprocess.py
```

Creates 3 non-IID hospital CSV files in `data/processed/`:

| Hospital | Patients | Profile | Stroke Rate |
|----------|----------|---------|------------|
| 1 | ~1700 | Elderly / hypertension | ~12% |
| 2 | ~1400 | Young / healthy | ~2% |
| 3 | ~2000 | Mixed / rural | ~5% |

## Step 3 — Run federated learning

### Option A: Simulation (easiest — one terminal)

```bash
python simulate.py
```

All 3 hospitals train inside a single process. Flower handles the coordination.

### Option B: Multi-terminal (closer to real deployment)

```bash
# Terminal 1 — server
python server.py

# Terminal 2 — Hospital 1
python client.py --hospital 1

# Terminal 3 — Hospital 2
python client.py --hospital 2

# Terminal 4 — Hospital 3
python client.py --hospital 3
```

## Step 4 — View results in MLflow

```bash
mlflow ui
# Open http://localhost:5000
```

---

## File overview

```
local_dev/
├── preprocess.py   # CSV → 3 hospital splits
├── model.py        # Shared StrokeNet (MLP)
├── simulate.py     # Option A: single-process FL
├── server.py       # Option B: FL server
├── client.py       # Option B: FL client (one per hospital)
├── requirements.txt
└── data/
    ├── raw/        # ← put Kaggle CSV here
    └── processed/  # ← auto-generated by preprocess.py
```

## When you're ready for cloud

The same `model.py`, `server.py`, and `client.py` drop directly into Docker containers.
Only change: swap `localhost:8080` → EKS service address.
