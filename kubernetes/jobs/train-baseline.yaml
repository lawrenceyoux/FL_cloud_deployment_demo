# kubernetes/jobs/train-baseline.yaml
#
# Kubernetes Job that runs Phase 3 baseline training on EKS.
# The training process logs all metrics + model artifacts to the
# MLflow server running in the mlops namespace.
#
# This file is a TEMPLATE — three variables are substituted by the
# "Train Baseline on EKS" GitHub Actions workflow before applying:
#   FL_IMAGE      — ECR image URI  (e.g. 123456789.dkr.ecr.us-east-1.amazonaws.com/fl-stroke:abc123)
#   TRAIN_EPOCHS  — number of training epochs (default: 50)
#   TRAIN_MODEL   — model architecture: simple | embeddings (default: embeddings)
#   TRAIN_LOSS    — loss function: weighted_bce | focal | bce (default: weighted_bce)
#   RUN_ID        — short git SHA / timestamp injected by workflow for unique Job naming
#
# To apply manually (after setting the env vars):
#   export FL_IMAGE=<ecr-uri>  TRAIN_EPOCHS=50  TRAIN_MODEL=embeddings TRAIN_LOSS=weighted_bce  RUN_ID=manual
#   envsubst < kubernetes/jobs/train-baseline.yaml | kubectl apply -f -
#
# To stream logs after applying:
#   kubectl logs -f job/train-baseline-${RUN_ID} -n federated-learning
---
apiVersion: batch/v1
kind: Job
metadata:
  name: train-baseline-${RUN_ID}
  namespace: federated-learning
  labels:
    app: fl-training
    phase: baseline
    run-id: "${RUN_ID}"
spec:
  # Do not restart on failure — surface the error in logs
  backoffLimit: 0
  # Clean up 10 minutes after completion so the Job doesn't clutter the namespace
  ttlSecondsAfterFinished: 600
  template:
    metadata:
      labels:
        app: fl-training
        phase: baseline
        run-id: "${RUN_ID}"
    spec:
      restartPolicy: Never
      # fl-trainer ServiceAccount is created by train-eks.yml before the Job
      # is applied.  For S3 model upload, annotate the SA with an IRSA role:
      #   eks.amazonaws.com/role-arn: arn:aws:iam::<ACCOUNT>:role/fl-trainer-s3
      serviceAccountName: mlflow-sa

      containers:
      - name: trainer
        image: ${FL_IMAGE}
        command: ["python", "-m", "src.train_baseline"]
        args:
          - "--epochs"
          - "${TRAIN_EPOCHS}"
          - "--model"
          - "${TRAIN_MODEL}"
          - "--loss"
          - "${TRAIN_LOSS}"

        env:
        # ── MLflow tracking ──────────────────────────────────────────
        - name: MLFLOW_TRACKING_URI
          valueFrom:
            configMapKeyRef:
              name: fl-config
              key: MLFLOW_TRACKING_URI
        # ── AWS region (needed if USE_S3=1) ─────────────────────────
        - name: AWS_REGION
          valueFrom:
            configMapKeyRef:
              name: fl-config
              key: AWS_REGION
        # ── Data: default is baked-in image data; set USE_S3=1 to
        #    pull fresh splits from S3 after the data-pipeline runs ──
        - name: USE_S3
          value: "0"
        # Uncomment below and set USE_S3=1 to read hospital data from S3:
        # - name: S3_RAW_BUCKET
        #   value: "fl-demo-data-hospital-1"

        # ── Silence noisy git-python warning (no git in container) ────
        - name: GIT_PYTHON_REFRESH
          value: "quiet"

        # ── S3 model artifact upload ────────────────────────────────
        # Set USE_S3_ARTIFACTS=0 to skip S3 upload and log to MLflow only.
        - name: USE_S3_ARTIFACTS
          value: "1"
        - name: S3_MODEL_BUCKET
          valueFrom:
            configMapKeyRef:
              name: fl-config
              key: S3_MODEL_BUCKET
        # AWS credentials for S3 upload.
        # Preferred: annotate mlflow-sa with IRSA role ARN (remove these entries).
        # Demo fallback: aws-fl-creds Secret created by train-eks.yml workflow.
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: aws-fl-creds
              key: AWS_ACCESS_KEY_ID
              optional: true   # safe to omit when using IRSA
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: aws-fl-creds
              key: AWS_SECRET_ACCESS_KEY
              optional: true   # safe to omit when using IRSA

        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "2"
